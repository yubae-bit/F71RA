---
title: "Class 3 Slides (Additional Material from Lecture)"
format: html
editor: visual
---

## Week 4 (2/10/2023)

Today we are going to explore "Factors in R" and "Linear Regression".

## Factors

First load the following libraries:

```{r}
library(forcats)   
library(ggplot2)
library(tidyverse)
```

### Sorting a vector

Here is a vector with the names of some months, which we want to sort, but can't use the sort function.

```{r}
# Vector with the names of some months:
x1 <- c("Dec", "Apr", "Jan", "Mar")
# We want to sort this vector but sort()
# will not produce the desired outcome in this case
sort(x1)
```

**Q: Instead, what could we do instead?**

```{r}

```

### Star Wars Example

Star Wars Data: A summary of the frequency of each species in the star wars universe.

First attach the `starwars` dataframe from `dplyr`

```{r}

```

Suppose that we want to a summary of the frequency of each species in the star wars universe, how can we do that?

```{r}

```

We observe that several species have very low frequency so it would make sense to lump them together using the `fct_lump()` function and create a new group called "other" which, for example, will include all the species with frequency less than 3. How can we do that?

```{r}

```

Suppose now, that we want to visualize the frequency of eye colors of all the characters in the star wars universe. How can we do that?

```{r}

```

Also, we can order the bars in the previous chart according to their frequency using the `fct_infreq()` function. How can we do that?

```{r}

```

Finally, we may want to visualize the summary statistics of a certain variable based on a specific categorical feature.

For example, it is interesting to see how average mass of the species in the star wars universe varies across different eye colors. How can we do that?

```{r}

```

Finally, we can reorder factor levels by sorting along another variable using the `fct_reorder()` function. As an example we will reorder the levels of the variable eye color according to the variable average mass. How can we do that?

```{r}

```

## Linear Regression

Linear Regression is a supervised machine learning algorithm which is used to predict the value of an outcome variable, or response, Y, based on one or more input features, or explanatory, variables X.

Suppose that Yi is the ith observation of the dependent variable and Xij is ith observation of the jth independent variable, for i = 1, \..., n and j = 1, 2, \..., p. Then, the basic model for multiple linear regression is X and the response variable Y.

$$Y_i = \beta_0 + \beta_1x_{1i} + \beta_2x_{2i} + ... + \beta_px{pi}+\varepsilon_i$$ where $\varepsilon_i \sim N(0,\sigma^2)$ is an i.i.d. random variable.

A multiple linear regression can be fitted with the `lm()` function in R. In our numerical analysis, we will demonstrate linear regression in a simple and easy to understand fashion by using the built-in data set "`cars`" that comes with R by default.\

Response variable Y:

-   mpg (miles/gallon)\

Explanatory Variables X:

-   cyl (Number of cylinders),

-   hp (gross horsepower) and

-   wt (weight).

First load the dataset below

```{r}

```

Investigate the relationship between the response `mpg` and features: `cyl`, `hp` and `wt`, by fitting a linear regression model.

```{r}

```

The estimated regression coefficients $\beta_i$, $i = 1,...,3$ are shown in the 'Estimate' column.

The fitted linear model is then:\
$$\hat{mpg} = \hat{\beta_0} - \hat{\beta_1}cyl - \hat{\beta_2}hp - \hat{\beta_3}wt + \varepsilon_i$$

**Q: Replace the** $\hat\beta_i$ **above with the values in the fitted model above that is written in latex.**

**Look at the significance codes. What do they tell us?**

### Residuals

A good way to test the quality of the fit of the model is via a graphical investigation of the residuals $\varepsilon_i$, which are the differences between the real values and the predicted values $\varepsilon_i = y_i - \hat{y_i}$.

Access the residuals of a linear model, use `residuals()` function and plot all the difference plots.

```{r}

```

The pattern of residuals shown in plot should exhibit a random pattern (fluctuate around 0).

Quantile-Quantile (QQ) plots) let you check that the data meet the assumption of normality. In particular, Q-Q plots take your sample data, sort it in ascending order, and then plot them versus the quantiles calculated from a theoretical distribution, in this case the normal distribution. If the residuals are from a normal population, they should fall close to the straight line.

### Goodness-of-fit

We can also look at $R^2$ and $\bar{R^2}$ (adjusted $R^2$) from `summary(fitted LM).` Their formulas are:

$$
R^2 = 1 - \frac{\sum_i(y_i - \hat{y_i})^2}{\sum_i(y_i - \bar{y_i})^2} \text{   and   } \bar{R}^2 = 1 - (1-R^2)\frac{n-1}{n-p-1}
$$

-   $R^2$ is defined as the proportion of the total variability explained by the regression model.

-   One problem with this $R^2$ is that it invariably increases as you add more explanatory variables $x$ to your model. This encourages adding extra useless features.

-   The adjusted $\bar{R}^2$ helps to mitigate this issue by penalizing additional variables.
